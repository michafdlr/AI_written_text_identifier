{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use transfer-learning with huggingface-transformers library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and make it accessible for huggingface environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import (AutoTokenizer, \n",
    "                          TFAutoModel,\n",
    "                          TFAutoModelForSequenceClassification\n",
    "                          )\n",
    "from datasets import Dataset, DatasetDict, load_from_disk # to use huggingface datasets\n",
    "from detector.utils import load_data, divide_frame\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers, callbacks, Model\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit, RandomizedSearchCV\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = (data[\"train\"].reset_index(drop=True), \n",
    "                    data[\"valid\"].reset_index(drop=True), \n",
    "                    data[\"test\"].reset_index(drop=True))\n",
    "\n",
    "def remove_newline(text: str) -> str:\n",
    "    return text.replace(\"\\n\", \" \")\n",
    "\n",
    "\n",
    "for df in [train, val, test]:\n",
    "    df[\"text\"] = df[\"text\"].apply(remove_newline)\n",
    "    df[\"text_length\"] = df['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_small, train_medium, train_long = divide_frame(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124936\n",
      "250122\n",
      "124942\n"
     ]
    }
   ],
   "source": [
    "for df in [train_small, train_medium, train_long]:\n",
    "    print(df.shape[0])\n",
    "\n",
    "train_sample = pd.concat([train_small.sample(10_000, random_state=1), \n",
    "                          train_medium.sample(20_000, random_state=1),\n",
    "                          train_long.sample(10_000, random_state=1)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>AI</th>\n",
       "      <th>text_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"I didn't even know what a baby looked like un...</td>\n",
       "      <td>1</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In this video, watch as an electric eel can cl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IOTA is divisible, fungible, durable , portabl...</td>\n",
       "      <td>0</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>× Report Chanel Preston And Ryan Ryans Just A ...</td>\n",
       "      <td>0</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best-selling film of 2012 starring Christi...</td>\n",
       "      <td>1</td>\n",
       "      <td>987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>BANGUI, Central African Republic (AP) — A day ...</td>\n",
       "      <td>1</td>\n",
       "      <td>4709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>So what world view is under assault by populis...</td>\n",
       "      <td>0</td>\n",
       "      <td>5219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>This is a list of the most frequently asked qu...</td>\n",
       "      <td>1</td>\n",
       "      <td>5083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>Gerardo Mora/GettyImages.  Mitt Romney has a p...</td>\n",
       "      <td>0</td>\n",
       "      <td>4951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>I believe our world today is one that is in cr...</td>\n",
       "      <td>1</td>\n",
       "      <td>4998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  AI  text_length\n",
       "0      \"I didn't even know what a baby looked like un...   1          264\n",
       "1      In this video, watch as an electric eel can cl...   1         1043\n",
       "2      IOTA is divisible, fungible, durable , portabl...   0          529\n",
       "3      × Report Chanel Preston And Ryan Ryans Just A ...   0          330\n",
       "4      The best-selling film of 2012 starring Christi...   1          987\n",
       "...                                                  ...  ..          ...\n",
       "39995  BANGUI, Central African Republic (AP) — A day ...   1         4709\n",
       "39996  So what world view is under assault by populis...   0         5219\n",
       "39997  This is a list of the most frequently asked qu...   1         5083\n",
       "39998  Gerardo Mora/GettyImages.  Mitt Romney has a p...   0         4951\n",
       "39999  I believe our world today is one that is in cr...   1         4998\n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = Dataset.from_pandas(train_sample, split=\"train\")\n",
    "ds_val = Dataset.from_pandas(val, split=\"valid\")\n",
    "ds_test = Dataset.from_pandas(test, split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pack datasets into a dictionary to tokenize them in parallel\n",
    "ds_dict = DatasetDict({\"train\": ds_train, \"valid\": ds_val, \"test\": ds_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'AI', 'text_length'],\n",
       "        num_rows: 40000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'AI', 'text_length'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'AI', 'text_length'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tokenizer suitable for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'roberta-large'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_checkpoint(name: str=\"distilbert\", \n",
    "                     large: bool=True,\n",
    "                     uncased: bool=True) -> str:\n",
    "    model_ckpt = f'{name}-large' if large else f'{name}-base'\n",
    "    return f'{model_ckpt}-uncased' if uncased else model_ckpt\n",
    "\n",
    "model_ckpt = model_checkpoint(name=\"roberta\",large=True, uncased=False)\n",
    "# define the tokenizer the model was trained with\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model_ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 7), dtype=int32, numpy=array([[   0, 9226,   16,   10, 1296,  328,    2]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 7), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"this is a test!\", return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a tokenize function that tokenizes the text in batches\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    }
   ],
   "source": [
    "ds_encoded = ds_dict.map(tokenize, batched=True, batch_size=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'AI', 'text_length', 'input_ids', 'attention_mask']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_encoded[\"train\"].column_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option 1: Use pre-trained model as feature extractor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting last hidden layer of a BERT model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this approach the model-weights of our RoBERTA model are frozen and provide features for a classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFRobertaModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModel.from_pretrained(model_ckpt, from_pt=True) # load the model from the checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor: shape=(1, 6, 1024), dtype=float32, numpy=\n",
       "array([[[ 0.04603524, -0.00462841,  0.01070017, ..., -0.05166832,\n",
       "          0.10207281,  0.06168523],\n",
       "        [ 0.16665468, -0.10331246, -0.35997272, ...,  0.06356603,\n",
       "         -0.1478664 ,  0.08259304],\n",
       "        [ 0.36435974, -0.06037583, -0.32145458, ...,  0.09165369,\n",
       "          0.07294382,  0.12116899],\n",
       "        [-0.08846132, -0.09831417,  0.01492194, ..., -0.04664286,\n",
       "         -0.18895282,  0.1724447 ],\n",
       "        [ 0.07978453, -0.15301354, -0.12229724, ..., -0.16046473,\n",
       "          0.11752793,  0.00620504],\n",
       "        [ 0.06696582, -0.0087914 ,  0.03385552, ..., -0.0685569 ,\n",
       "          0.08994152,  0.01962573]]], dtype=float32)>, pooler_output=<tf.Tensor: shape=(1, 1024), dtype=float32, numpy=\n",
       "array([[ 0.15439375,  0.71824986,  0.45034176, ..., -0.00599452,\n",
       "         0.40904945, -0.3544111 ]], dtype=float32)>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"this is a test\"\n",
    "inputs = tokenizer(text, return_tensors=\"tf\")\n",
    "outputs = model(**inputs)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 6, 1024])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape #output [batch_size, n_tokens, hidden_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1024])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for classification it is common practice use hidden state associated to start \n",
    "# of sequence token\n",
    "outputs.last_hidden_state[:, 0].shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract last hidden state for whole dataset\n",
    "def extract_hidden_states(batch):\n",
    "    inputs = {k: v for k,v in batch.items() if k in tokenizer.model_input_names}\n",
    "    last_hidden_state = model(**inputs).last_hidden_state\n",
    "    return {\"hidden_state\": last_hidden_state[:, 0].numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_encoded.set_format(\"tensorflow\", columns=[\"input_ids\", \"attention_mask\", \"AI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_state': array([[-0.33420086, -0.16058649, -0.16484469, ...,  0.27835876,\n",
       "         -0.0556819 ,  0.37149817],\n",
       "        [-0.16613328, -0.23028064, -0.22600123, ...,  0.29751363,\n",
       "         -0.30976388,  0.5156858 ]], dtype=float32)}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_hidden_states(ds_encoded[\"train\"][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/transformers/generation/tf_utils.py:465: UserWarning: `seed_generator` is deprecated and will be removed in a future version.\n",
      "  warnings.warn(\"`seed_generator` is deprecated and will be removed in a future version.\", UserWarning)\n",
      "                                                                   \r"
     ]
    }
   ],
   "source": [
    "ds_hidden = ds_encoded.map(extract_hidden_states, batched=True, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'AI', 'text_length', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 40000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'AI', 'text_length', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'AI', 'text_length', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                 \r"
     ]
    }
   ],
   "source": [
    "ds_hidden.save_to_disk(f\"hidden_states_{model_ckpt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hidden = load_from_disk(f\"hidden_states_{model_ckpt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'AI', 'text_length', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 40000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'AI', 'text_length', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'AI', 'text_length', 'input_ids', 'attention_mask', 'hidden_state'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_hidden"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing data to train model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now using these hidden states to train a relatively simple classifier to predict if text is AI written or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(ds_hidden[\"train\"][\"hidden_state\"])\n",
    "X_val = np.array(ds_hidden[\"valid\"][\"hidden_state\"])\n",
    "X_test = np.array(ds_hidden[\"test\"][\"hidden_state\"])\n",
    "\n",
    "y_train = np.array(ds_hidden[\"train\"][\"AI\"])\n",
    "y_val = np.array(ds_hidden[\"valid\"][\"AI\"])\n",
    "y_test = np.array(ds_hidden[\"test\"][\"AI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.17704922,  0.00966936, -0.16979757, ..., -0.05526693,\n",
       "         0.26920223,  0.255841  ],\n",
       "       [-0.20750733, -0.3828969 , -0.23853931, ..., -0.06183667,\n",
       "         0.51362616,  0.57837814],\n",
       "       [-0.14452401, -0.04512678,  0.01497217, ..., -0.13479084,\n",
       "         0.0740034 ,  0.64472616],\n",
       "       ...,\n",
       "       [-0.20454003, -0.07451978, -0.3736105 , ..., -0.06127113,\n",
       "         0.49450588,  0.55551225],\n",
       "       [-0.16704421, -0.33564562, -0.4231589 , ...,  0.08641999,\n",
       "         0.61370015,  0.44469708],\n",
       "       [-0.05228056, -0.08852108, -0.20443952, ..., -0.14951706,\n",
       "         0.6424493 ,  0.36885926]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 768), (40000,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_search = np.vstack((X_train, X_val))\n",
    "y_search = np.hstack((y_train, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_search.shape, y_search.shape\n",
    "split = PredefinedSplit([-1]*X_train.shape[0]+[0]*X_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(max_iter=5000)\n",
    "\n",
    "params = {\"C\":[2**k for k in range(-2, 5)]}\n",
    "\n",
    "search = GridSearchCV(lr_clf,\n",
    "                      param_grid=params,\n",
    "                      n_jobs=-1,\n",
    "                      cv = split,\n",
    "                      scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=LogisticRegression(max_iter=5000), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.25, 0.5, 1, 2, 4, 8, 16]}, scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=LogisticRegression(max_iter=5000), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [0.25, 0.5, 1, 2, 4, 8, 16]}, scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=5000)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=5000)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=LogisticRegression(max_iter=5000), n_jobs=-1,\n",
       "             param_grid={'C': [0.25, 0.5, 1, 2, 4, 8, 16]}, scoring='accuracy')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X_search, y_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf_best = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_models/lr_clf_best_distilbert-base-uncased.joblib']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lr_clf_best, f\"trained_models/lr_clf_best_{model_ckpt}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.871"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_model[\"logistic_regression\"] = lr_clf_best.score(X_test, y_test)\n",
    "scores_model[\"logistic_regression\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc = SVC(random_state=1)\n",
    "\n",
    "# params_svc = {\n",
    "#     'C': [0.5, 1, 2],\n",
    "#     #'degree': 3,\n",
    "#     'kernel': ['linear']\n",
    "#  }\n",
    "\n",
    "# search_svc = GridSearchCV(\n",
    "#     svc,\n",
    "#     param_grid=params_svc,\n",
    "#     n_jobs=-1,\n",
    "#     cv=split,\n",
    "#     scoring=\"accuracy\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_svc.fit(X_search, y_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_best = search_svc.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# svc_best.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_clf = RandomForestClassifier(random_state=1, verbose=1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params_rf = {\n",
    "#  'bootstrap': [True, False],\n",
    "#  'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "#  'max_features': ['auto', 'sqrt'],\n",
    "#  'min_samples_leaf': [1, 2, 4],\n",
    "#  'min_samples_split': [2, 5, 10],\n",
    "#  'n_estimators': [200, 400, 600, 800, 1000]\n",
    "#  }\n",
    "\n",
    "# random_search = RandomizedSearchCV(rf_clf,\n",
    "#                                    param_distributions=params_rf,\n",
    "#                                    n_iter=5,\n",
    "#                                    scoring=\"accuracy\",\n",
    "#                                    n_jobs=-1,\n",
    "#                                    cv=split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/Users/michaelfiedler/.pyenv/versions/3.10.6/envs/AI_written_text_identifier/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:   21.8s\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  4.4min finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=10)]: Done 600 out of 600 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  4.8min finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=10)]: Done 600 out of 600 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=-1)]: Done 780 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:  5.5min finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=10)]: Done 800 out of 800 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=-1)]: Done 780 tasks      | elapsed:  6.5min\n",
      "[Parallel(n_jobs=-1)]: Done 780 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:  6.7min finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=10)]: Done 800 out of 800 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  7.1min finished\n",
      "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=10)]: Done 1000 out of 1000 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 180 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done 430 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 780 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=1,\n",
       "                                                    verbose=1),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000]},\n",
       "                   scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=1,\n",
       "                                                    verbose=1),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, None],\n",
       "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [200, 400, 600, 800,\n",
       "                                                         1000]},\n",
       "                   scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=1, verbose=1)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_jobs=-1, random_state=1, verbose=1)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=1,\n",
       "                                                    verbose=1),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000]},\n",
       "                   scoring='accuracy')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random_search.fit(X_search, y_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_search.best_score_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(booster = 'gblinear', \n",
    "                        n_estimators=1000, \n",
    "                        seed=1, \n",
    "                        random_state=1)\n",
    "#xgb_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {\n",
    "    'reg_lambda': [k*0.1 for k in range(11)]\n",
    "    }\n",
    "\n",
    "search_xgb = GridSearchCV(\n",
    "    xgb_clf,\n",
    "    param_grid=params_xgb,\n",
    "    n_jobs=-1,\n",
    "    cv=split,\n",
    "    scoring=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=1000, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=1, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;reg_lambda&#x27;: [0.0, 0.1, 0.2, 0.30000000000000004, 0.4,\n",
       "                                        0.5, 0.6000000000000001,\n",
       "                                        0.7000000000000001, 0.8, 0.9, 1.0]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=1000, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=1, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;reg_lambda&#x27;: [0.0, 0.1, 0.2, 0.30000000000000004, 0.4,\n",
       "                                        0.5, 0.6000000000000001,\n",
       "                                        0.7000000000000001, 0.8, 0.9, 1.0]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
       "             estimator=XGBClassifier(base_score=None, booster='gblinear',\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type...\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=1000, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=1, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'reg_lambda': [0.0, 0.1, 0.2, 0.30000000000000004, 0.4,\n",
       "                                        0.5, 0.6000000000000001,\n",
       "                                        0.7000000000000001, 0.8, 0.9, 1.0]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_xgb.fit(X_search, y_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best = search_xgb.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster='gblinear', callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=1000, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=1, ...)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_models/xgb_best_distilbert-base-uncased.joblib.dat']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(xgb_best, f\"trained_models/xgb_best_{model_ckpt}.joblib.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model[\"xgb\"] = xgb_best.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8699"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_model[\"xgb\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RidgeClassifierCV(alphas=[0.99, 0.1, 0.11],\n",
       "                  cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RidgeClassifierCV</label><div class=\"sk-toggleable__content\"><pre>RidgeClassifierCV(alphas=[0.99, 0.1, 0.11],\n",
       "                  cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RidgeClassifierCV(alphas=[0.99, 0.1, 0.11],\n",
       "                  cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_clf = RidgeClassifierCV(alphas=[0.99,0.1, 0.11], cv=split)\n",
    "\n",
    "ridge_clf.fit(X_search, y_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trained_models/ridge_clf_distilbert-base-uncased.joblib']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(ridge_clf, f\"trained_models/ridge_clf_{model_ckpt}.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_model[\"ridge\"] = ridge_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8719"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_model[\"ridge\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"basic_nn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 768)]             0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                49216     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53441 (208.75 KB)\n",
      "Trainable params: 53441 (208.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_inputs = keras.Input(shape=(X_train.shape[1],))\n",
    "x = layers.Dense(64, activation='gelu')(nn_inputs)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(64, activation='gelu')(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "nn_model = Model(inputs=nn_inputs, outputs = outputs, name=\"basic_nn\")\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "num_train_examples = X_train.shape[0]\n",
    "batch_size = 32\n",
    "init_lr = 5e-4\n",
    "\n",
    "decay_steps = num_train_examples // batch_size\n",
    "\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(initial_learning_rate=init_lr,\n",
    "                                                    decay_steps=decay_steps,\n",
    "                                                    decay_rate=0.9)\n",
    "\n",
    "es = callbacks.EarlyStopping(monitor=\"val_binary_accuracy\",\n",
    "                             mode=\"max\",\n",
    "                             patience=5,\n",
    "                             restore_best_weights=True)\n",
    "\n",
    "nn_model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                 metrics=[keras.metrics.BinaryAccuracy()],\n",
    "                 optimizer = optimizers.Adam(lr_schedule))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-23 17:40:45.210349: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1245/1250 [============================>.] - ETA: 0s - loss: 0.4187 - binary_accuracy: 0.8084"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-23 17:40:54.039326: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 10s 8ms/step - loss: 0.4183 - binary_accuracy: 0.8086 - val_loss: 0.3592 - val_binary_accuracy: 0.8426\n",
      "Epoch 2/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3411 - binary_accuracy: 0.8500 - val_loss: 0.3357 - val_binary_accuracy: 0.8541\n",
      "Epoch 3/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3208 - binary_accuracy: 0.8628 - val_loss: 0.3019 - val_binary_accuracy: 0.8716\n",
      "Epoch 4/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.3056 - binary_accuracy: 0.8698 - val_loss: 0.3406 - val_binary_accuracy: 0.8478\n",
      "Epoch 5/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.2926 - binary_accuracy: 0.8768 - val_loss: 0.2942 - val_binary_accuracy: 0.8737\n",
      "Epoch 6/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2839 - binary_accuracy: 0.8791 - val_loss: 0.2905 - val_binary_accuracy: 0.8736\n",
      "Epoch 7/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2759 - binary_accuracy: 0.8834 - val_loss: 0.2789 - val_binary_accuracy: 0.8814\n",
      "Epoch 8/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2697 - binary_accuracy: 0.8863 - val_loss: 0.2879 - val_binary_accuracy: 0.8762\n",
      "Epoch 9/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2640 - binary_accuracy: 0.8885 - val_loss: 0.2731 - val_binary_accuracy: 0.8824\n",
      "Epoch 10/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2576 - binary_accuracy: 0.8917 - val_loss: 0.2785 - val_binary_accuracy: 0.8806\n",
      "Epoch 11/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2530 - binary_accuracy: 0.8950 - val_loss: 0.2726 - val_binary_accuracy: 0.8835\n",
      "Epoch 12/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2484 - binary_accuracy: 0.8947 - val_loss: 0.2823 - val_binary_accuracy: 0.8780\n",
      "Epoch 13/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.2446 - binary_accuracy: 0.8981 - val_loss: 0.2706 - val_binary_accuracy: 0.8841\n",
      "Epoch 14/100\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 0.2415 - binary_accuracy: 0.8986 - val_loss: 0.2736 - val_binary_accuracy: 0.8835\n",
      "Epoch 15/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2378 - binary_accuracy: 0.9009 - val_loss: 0.2743 - val_binary_accuracy: 0.8841\n",
      "Epoch 16/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2361 - binary_accuracy: 0.9013 - val_loss: 0.2783 - val_binary_accuracy: 0.8830\n",
      "Epoch 17/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2331 - binary_accuracy: 0.9028 - val_loss: 0.2711 - val_binary_accuracy: 0.8847\n",
      "Epoch 18/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2310 - binary_accuracy: 0.9053 - val_loss: 0.2683 - val_binary_accuracy: 0.8871\n",
      "Epoch 19/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2283 - binary_accuracy: 0.9064 - val_loss: 0.2680 - val_binary_accuracy: 0.8861\n",
      "Epoch 20/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 0.2260 - binary_accuracy: 0.9054 - val_loss: 0.2718 - val_binary_accuracy: 0.8857\n",
      "Epoch 21/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2257 - binary_accuracy: 0.9060 - val_loss: 0.2693 - val_binary_accuracy: 0.8867\n",
      "Epoch 22/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 0.2221 - binary_accuracy: 0.9089 - val_loss: 0.2670 - val_binary_accuracy: 0.8878\n",
      "Epoch 23/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 0.2218 - binary_accuracy: 0.9074 - val_loss: 0.2669 - val_binary_accuracy: 0.8868\n",
      "Epoch 24/100\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 0.2201 - binary_accuracy: 0.9093 - val_loss: 0.2702 - val_binary_accuracy: 0.8867\n",
      "Epoch 25/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2201 - binary_accuracy: 0.9095 - val_loss: 0.2697 - val_binary_accuracy: 0.8877\n",
      "Epoch 26/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2178 - binary_accuracy: 0.9097 - val_loss: 0.2674 - val_binary_accuracy: 0.8866\n",
      "Epoch 27/100\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 0.2162 - binary_accuracy: 0.9118 - val_loss: 0.2706 - val_binary_accuracy: 0.8870\n"
     ]
    }
   ],
   "source": [
    "history = nn_model.fit(X_train, y_train,\n",
    "             batch_size=batch_size,\n",
    "             epochs=num_epochs,\n",
    "             validation_data=(X_val, y_val),\n",
    "             callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"val_binary_accuracy\"])\n",
    "plt.plot(history.history[\"binary_accuracy\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 5ms/step - loss: 0.2749 - binary_accuracy: 0.8834\n"
     ]
    }
   ],
   "source": [
    "scores_model[\"neural_network\"] = {\"score\": nn_model.evaluate(X_test, y_test)[1],\n",
    "                                  \"model\": nn_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.883400022983551,\n",
       " 'model': <keras.src.engine.functional.Functional at 0x459f31510>}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_model[\"neural_network\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn_model_distilbert-base-uncased/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn_model_distilbert-base-uncased/assets\n"
     ]
    }
   ],
   "source": [
    "nn_model.save(f\"nn_model_{model_ckpt}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Prediction for input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9581640348759896"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = '''In recent years, we have witnessed a remarkable revolution in the field of artificial intelligence (AI). \n",
    "The rapid advancements in machine learning and neural networks have unlocked unprecedented capabilities, enabling AI \n",
    "systems to perform complex tasks and mimic human intelligence with remarkable accuracy. \n",
    "This revolution has had a profound impact on various aspects of our lives, including communication, entertainment, \n",
    "and information dissemination.'''\n",
    "#nn_model.predict(model(**tokenizer(test_text, return_tensors='tf')).last_hidden_state[:,0].numpy())[0][0]\n",
    "lr_clf_best.predict_proba(model(**tokenizer(test_text, return_tensors='tf')).last_hidden_state[:,0].numpy())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text_input: str, model_name: str=\"nn\") -> float:\n",
    "    '''outputs the probability of the text being AI written\n",
    "    ---\n",
    "    text_input: text to be classified\n",
    "    ---\n",
    "    model_name: model to be used for classification. Options are \"nn\" \n",
    "    for neural network, \"xgb\" for xgboost,\n",
    "    \"lr\" for logistic regression, \"ridge\" for ridge classifier.\n",
    "    '''\n",
    "    inputs = tokenizer(text_input, return_tensors=\"tf\")\n",
    "    outputs = model(**inputs)\n",
    "    hidden_states = outputs.last_hidden_state[:, 0].numpy()\n",
    "    proba = None\n",
    "    class_pred = None\n",
    "    if model_name == \"nn\":\n",
    "        nn_model = keras.models.load_model(f\"nn_model_{model_ckpt}\")\n",
    "        proba = nn_model.predict(hidden_states, verbose=0)[0][0]\n",
    "    elif model_name == \"lr\":\n",
    "        lr_clf_best = load(f\"trained_models/lr_clf_best_{model_ckpt}.joblib\")\n",
    "        proba = lr_clf_best.predict_proba(hidden_states)[0][1]\n",
    "    elif model_name == \"ridge\":\n",
    "        ridge_clf = load(f\"trained_models/ridge_clf_{model_ckpt}.joblib\")\n",
    "        proba = ridge_clf.decision_function(hidden_states)[0]\n",
    "    elif model_name == \"xgb\":\n",
    "        xgb_best = load(f\"trained_models/xgb_best_{model_ckpt}.joblib.dat\")\n",
    "        proba = xgb_best.predict_proba(hidden_states)[0][1]\n",
    "    else:\n",
    "        raise ValueError(\"model must be one of 'nn', 'lr' or 'ridge'\")\n",
    "    if proba > 0.5:\n",
    "        class_pred = \"AI written\"\n",
    "    else:\n",
    "        class_pred = \"not AI written\"\n",
    "    print(f'''Probability of text being AI written: {proba:.2f}\n",
    "The prediction therfore is that the text is {class_pred}''')\n",
    "    return proba, class_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of text being AI written: 0.97\n",
      "The prediction therfore is that the text is AI written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-23 18:23:35.253961: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.96681577, 'AI written')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction(test_text, model_name=\"nn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_written_text_identifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
