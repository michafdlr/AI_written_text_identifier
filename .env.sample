PATH_DATA='/mnt/c/Users/Eren_Kiliclar/AppData/Local/Programs/Microsoft VS Code/data/'
LOCAL_REGISTRY_PATH=models
TRAIN_SIZE = 70000
TOKENIZERS_PARALLELISM=false
TF_CPP_MIN_LOG_LEVEL=2

# Data source, replace with 'cloud' to source from cloud (depending on how you write your functions)
DATA_SOURCE=cloud
MODEL_TARGET=local

# GCP Project
PROJECT_ID=ai-written-text-identifier
REGION=europe-west1

# On GCP console, create a new service account for your project, create a new key,
# save it on your local drive (make sure its .gitignored!), and add the path to it here
GOOGLE_APPLICATION_CREDENTIALS=credentials.json

# Cloud Storage
BUCKET_NAME=ai_text_identifier_bucket
# Folder in your bucket where raw_data is stored
RAW_DATA_LOCATION=raw_data
# Folder in your bucket where your model is stored
MODELS_LOCATION=models

# BigQuery (only if you use it)
MULTI_REGION=EU
DATASET=your_dataset

# Compute Engine (only if you use it)
INSTANCE=instance_name

# Model Lifecycle
MLFLOW_TRACKING_URI=https://mlflow.lewagon.ai
MLFLOW_EXPERIMENT=project_name_experiment_<user.github_nickname>
MLFLOW_MODEL_NAME=project_name_<user.github_nickname>

# Docker
DOCKER_LOCAL_PORT=8080
DOCKER_IMAGE_NAME=project_name_api
GCR_MULTI_REGION=eu.gcr.io
